{"cells":[{"cell_type":"markdown","metadata":{"id":"UMHIH5UxQXbJ"},"source":[]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/home/osero/Desktop/CMPE/dinov2/preprocess/result_hand_left/0001/User_2_003/00001.jpg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[1;32m     42\u001b[0m     cropped_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcrop([x_min\u001b[38;5;241m-\u001b[39mpadding, y_min\u001b[38;5;241m-\u001b[39mpadding, x_max\u001b[38;5;241m+\u001b[39mpadding, y_max\u001b[38;5;241m+\u001b[39mpadding])\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mcropped_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_img_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Change this path as needed\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# plt.imshow(cropped_img)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# close the file\u001b[39;00m\n\u001b[1;32m     47\u001b[0m file\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.10/site-packages/PIL/Image.py:2563\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2563\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/osero/Desktop/CMPE/dinov2/preprocess/result_hand_left/0001/User_2_003/00001.jpg'"]}],"source":["import glob\n","import os\n","import pickle\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import shutil\n","\n","data_folder_path = '/home/osero/Downloads/mmpose-full/0001/'\n","img_folder = '/home/osero/Downloads/frame-full-c1080-s10/0001'\n","result_folder = 'result_hand_left/0001/'\n","\n","data_files = [os.path.basename(file) for file in glob.glob(os.path.join(data_folder_path, '*')) if os.path.isfile(file)]\n","\n","padding = 0\n","for file_path in data_files:\n","    user_name = os.path.splitext(file_path)[0]\n","    data_path = data_folder_path + file_path\n","    file = open(data_path, 'rb')\n","\n","    # dump information to that file\n","    data = pickle.load(file)\n","\n","    frame_count = data['hand_left']['left_lunate_bone'].shape[0]\n","    save_folder = os.path.join(result_folder, user_name)\n","    if os.path.exists(save_folder):\n","        shutil.rmtree(save_folder)\n","\n","    os.makedirs(save_folder)\n","    for frame_number in range(0,frame_count):\n","        x_max = 0\n","        y_max = 0\n","        x_min = 1920\n","        y_min = 1080\n","        for finger_key, finger_value in data['hand_left'].items():\n","            cx = finger_value[frame_number][0]\n","            cy = finger_value[frame_number][1]\n","            if cx > x_max:\n","                x_max = cx\n","            if cx < x_min:\n","                x_min = cx\n","            if cy > y_max:\n","                y_max = cy\n","            if cy < y_min:\n","                y_min = cy\n","        img_path = \"%s/%s/%s.jpg\" % (img_folder, user_name, str(frame_number+1).zfill(5))\n","        result_img_path = \"%s/%s/%s.jpg\" % (result_folder, user_name, str(frame_number+1).zfill(5))\n","        img = Image.open(img_path)\n","        cropped_img = img.crop([x_min-padding, y_min-padding, x_max+padding, y_max+padding])\n","        cropped_img.save(result_img_path)  # Change this path as needed\n","        # plt.imshow(cropped_img)\n","        # plt.show()\n","    # close the file\n","    file.close()\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4544,"status":"ok","timestamp":1684076425211,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"qrg__PhVzf_s"},"outputs":[{"data":{"text/plain":["['00052.jpg',\n"," '00027.jpg',\n"," '00032.jpg',\n"," '00070.jpg',\n"," '00077.jpg',\n"," '00031.jpg',\n"," '00060.jpg',\n"," '00047.jpg',\n"," '00007.jpg',\n"," '00054.jpg',\n"," '00059.jpg',\n"," '00056.jpg',\n"," '00034.jpg',\n"," '00042.jpg',\n"," '00040.jpg',\n"," '00083.jpg',\n"," '00030.jpg',\n"," '00044.jpg',\n"," '00066.jpg',\n"," '00085.jpg',\n"," '00008.jpg',\n"," '00078.jpg',\n"," '00068.jpg',\n"," '00055.jpg',\n"," '00019.jpg',\n"," '00014.jpg',\n"," '00069.jpg',\n"," '00063.jpg',\n"," '00081.jpg',\n"," '00053.jpg',\n"," '00006.jpg',\n"," '00038.jpg',\n"," '00045.jpg',\n"," '00026.jpg',\n"," '00029.jpg',\n"," '00017.jpg',\n"," '00002.jpg',\n"," '00072.jpg',\n"," '00035.jpg',\n"," '00018.jpg',\n"," '00022.jpg',\n"," '00020.jpg',\n"," '00043.jpg',\n"," '00061.jpg',\n"," '00075.jpg',\n"," '00009.jpg',\n"," '00071.jpg',\n"," '00004.jpg',\n"," '00011.jpg',\n"," '00051.jpg',\n"," '00036.jpg',\n"," '00024.jpg',\n"," '00073.jpg',\n"," '00003.jpg',\n"," '00050.jpg',\n"," '00048.jpg',\n"," '00023.jpg',\n"," '00015.jpg',\n"," '00076.jpg',\n"," '00028.jpg',\n"," '00021.jpg',\n"," '00037.jpg',\n"," '00062.jpg',\n"," '00080.jpg',\n"," '00046.jpg',\n"," '00001.jpg',\n"," '00012.jpg',\n"," '00033.jpg',\n"," '00084.jpg',\n"," '00079.jpg',\n"," '00057.jpg',\n"," '00058.jpg',\n"," '00074.jpg',\n"," '00013.jpg',\n"," '00016.jpg',\n"," '00082.jpg',\n"," '00049.jpg',\n"," '00025.jpg',\n"," '00005.jpg',\n"," '00064.jpg',\n"," '00065.jpg',\n"," '00067.jpg',\n"," '00010.jpg',\n"," '00039.jpg',\n"," '00041.jpg']"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import glob\n","import os\n","folder_path = '/home/osero/Downloads/frame-full-c1080-s10/0001/User_5_001'\n","files = [os.path.basename(file) for file in glob.glob(os.path.join(folder_path, '*')) if os.path.isfile(file)]\n","files"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1728689938.970816   98346 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1728689938.989209   98346 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]}],"source":["import shutil\n","import cv2\n","import mediapipe as mp\n","\n","result_path = 'results_hand'\n","\n","# Initializing the Model\n","min_detection_confidence = 0.5\n","mpHands = mp.solutions.hands\n","hands = mpHands.Hands(\n","    static_image_mode = True,\n","    model_complexity = 1,\n","    min_detection_confidence = min_detection_confidence,\n","    max_num_hands = 2)\n","\n","def crop_hand_images (all_images):\n","    global counter_single, counter_none, counter_all\n","    # hands.reset()\n","    padding = 10\n","    for file_name, image in all_images:\n","        # Process the RGB image\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = hands.process(image)\n","        h, w, c = image.shape\n","        counter_all += 1\n","        # If hands are present in image(frame)\n","        if results.multi_hand_landmarks:\n","            for idx, handLMs in enumerate(results.multi_hand_landmarks):\n","                x_max = 0\n","                y_max = 0\n","                x_min = w\n","                y_min = h\n","                lmlist = []\n","                for lm in handLMs.landmark:\n","                    cx, cy = int(lm.x * w), int(lm.y * h)\n","                    if cx > x_max:\n","                        x_max = cx\n","                    if cx < x_min:\n","                        x_min = cx\n","                    if cy > y_max:\n","                        y_max = cy\n","                    if cy < y_min:\n","                        y_min = cy\n","\n","                hand_img = image[y_min-padding:y_max+padding,x_min-padding:x_max+padding]\n","                cv2.imwrite(result_path + '/' + file_name + '_h' + str(idx) + '.jpg', cv2.cvtColor(hand_img, cv2.COLOR_RGB2BGR))\n","\n","                # plt.imshow(Image.fromarray(image[y_min-padding:y_max+padding,x_min-padding:x_max+padding]))\n","                # plt.show()\n","                aaa = 5\n","\n","            if len(results.multi_handedness) != 2:\n","                # plt.imshow(Image.fromarray(image))\n","                # plt.show()\n","                counter_single += 1\n","\n","        else:\n","            counter_none += 1\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/osero/miniconda3/envs/dinov2/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"]},{"name":"stdout","output_type":"stream","text":["min_detection_confidence: 0.5\n","All: 7554\n","Missed: 291\n","Single: 1178\n"]}],"source":["import cv2 \n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","frame_sample_frequency = 8\n","\n","if os.path.exists(result_path):\n","    shutil.rmtree(result_path)\n","\n","os.makedirs(result_path)\n","\n","counter_single = 0\n","counter_none = 0\n","counter_all = 0\n","\n","for file_path in files:\n","    # Open the video file\n","    video_path = folder_path + file_path\n","    video_capture = cv2.VideoCapture(video_path)\n","\n","    # Get the total number of frames\n","    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frame_numbers = [i for i in range(0, total_frames, frame_sample_frequency)]\n","    all_images = []\n","\n","    for frame_number in frame_numbers:\n","            \n","        # Set the video capture to requested frame number\n","        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n","\n","        # Read the frame\n","        success, img = video_capture.read()\n","        if success:\n","            frame_file_path = os.path.splitext(file_path)[0] + '_f' + str(frame_number)\n","            all_images.append((frame_file_path, img))\n","        else:\n","            print('Error while reading image from a video')\n","            print('File:', file_path)\n","            print('total_frames:', total_frames)\n","            print('frame_number:', frame_number)\n","    \n","    create_hand_images(all_images)\n","\n","print('min_detection_confidence:', min_detection_confidence)\n","print('All:', counter_all)\n","print('Missed:', counter_none)\n","print('Single:', counter_single)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20218,"status":"ok","timestamp":1684076445425,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"N3eJdAr6zu37","outputId":"541a00fd-b382-4d11-fd53-114e67a9dfec"},"outputs":[{"name":"stderr","output_type":"stream","text":["libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n","\n","W0000 00:00:1728685068.261697   23403 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1728685068.277135   23403 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m counter_none \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name, image \u001b[38;5;129;01min\u001b[39;00m all_images:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Process the RGB image\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     results \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[1;32m     29\u001b[0m     h, w, c \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}],"source":["\n","# import shutil\n","# import cv2\n","# import mediapipe as mp\n","\n","# # Used to convert protobuf message\n","# # to a dictionary.\n","# from google.protobuf.json_format import MessageToDict\n","\n","# result_path = 'results_hand'\n","# if os.path.exists(result_path):\n","#     shutil.rmtree(result_path)\n","\n","# os.makedirs(result_path)\n","# # Initializing the Model\n","# min_detection_confidence = 0.5\n","# mpHands = mp.solutions.hands\n","# hands = mpHands.Hands(\n","#     static_image_mode=True,\n","#     model_complexity=1,\n","#     min_detection_confidence = min_detection_confidence,\n","#     max_num_hands=2)\n","\n","# padding = 10\n","# counter_single = 0\n","# counter_none = 0\n","# for file_name, image in all_images:\n","#     # Process the RGB image\n","#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","#     results = hands.process(image)\n","#     h, w, c = image.shape\n","\n","#     # If hands are present in image(frame)\n","#     if results.multi_hand_landmarks:\n","#         for idx, handLMs in enumerate(results.multi_hand_landmarks):\n","#             x_max = 0\n","#             y_max = 0\n","#             x_min = w\n","#             y_min = h\n","#             lmlist = []\n","#             for lm in handLMs.landmark:\n","#                 cx, cy = int(lm.x * w), int(lm.y * h)\n","#                 if cx > x_max:\n","#                     x_max = cx\n","#                 if cx < x_min:\n","#                     x_min = cx\n","#                 if cy > y_max:\n","#                     y_max = cy\n","#                 if cy < y_min:\n","#                     y_min = cy\n","#                 # lmlist.append([cx,cy])\n","#                 # cv2.circle(image,(cx,cy),5,(255,0,255),cv2.FILLED)\n","#             hand_img = image[y_min-padding:y_max+padding,x_min-padding:x_max+padding]\n","#             cv2.imwrite(result_path + '/' + file_name + '_h' + str(idx) + '.jpg', hand_img)\n","\n","#             # plt.imshow(Image.fromarray(image[y_min-padding:y_max+padding,x_min-padding:x_max+padding]))\n","#             # plt.show()\n","#             aaa = 5\n","\n","#         # Both Hands are present in image(frame)\n","#         if len(results.multi_handedness) != 2:\n","#             # plt.imshow(Image.fromarray(image))\n","#             # plt.show()\n","#                 # Display 'Both Hands' on the image\n","#             counter_single += 1\n","\n","#     else:\n","#         counter_none += 1\n","#     # # Display Video and when 'q' is entered, destroy the window\n","#     # cv2.imshow('Image', img)\n","# print('min_detection_confidence:', min_detection_confidence)\n","# print('All:', len(all_images))\n","# print('Missed:', counter_none)\n","# print('Single:', counter_single)\n","# bb = 5\n","\n","\n","# # import shutil\n","# # result_path = 'results_hand'\n","# # if os.path.exists(result_path):\n","# #     shutil.rmtree(result_path)\n","\n","# # os.makedirs(result_path)\n","\n","# # face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n","# # jdx = 0\n","# # for image in all_images:\n","# #     jdx += 1\n","# #     # Detect faces\n","# #     gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","# #     faces = face_cascade.detectMultiScale(gray_img, 1.2, minSize = [30,30])\n","# #     #plt.imshow(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n","# #     #plt.show()\n","# #     for idx, (x, y, w, h) in enumerate(faces):\n","# #         padding = 10\n","# #         face_img = image[y - padding:y + h + padding, x - padding:x + w + padding]\n","# #         cropped_head_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))\n","# #         #plt.imshow(cropped_head_pil)\n","# #         cv2.imwrite(result_path + '/' + str(jdx) + 'face' + str(idx) + '.jpg', face_img)\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMN1jKrWK4NzDyHzEG2r8BN","provenance":[]},"kernelspec":{"display_name":"dinov2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
